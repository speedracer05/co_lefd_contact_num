{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c24c8-e7fb-4e2e-adb5-49f8d6b3bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from urllib.parse import urljoin  # For handling relative URLs\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import logging\n",
    "\n",
    "# Configure logging for debug purposes\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Configure the Chrome WebDriver options for headless execution if preferred\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Comment this line to see browser actions\n",
    "\n",
    "# Start the Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84e48a-803f-4034-876c-2898f1bccdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions for Data Extraction\n",
    "\n",
    "# Function to format state to abbreviations\n",
    "def format_state(state_name):\n",
    "    # Dictionary of state abbreviations\n",
    "    state_abbr = {\n",
    "        \"California\": \"CA\",\n",
    "        \"Colorado\": \"CO\",\n",
    "        # Add other state mappings as needed\n",
    "    }\n",
    "    return state_abbr.get(state_name, state_name)  # Default to state_name if not found\n",
    "\n",
    "def format_phone(phone):\n",
    "    phone_digits = re.sub(r\"\\D\", \"\", phone)  # Remove non-digit characters\n",
    "    return f\"({phone_digits[:3]}) {phone_digits[3:6]}-{phone_digits[6:10]}\" if len(phone_digits) >= 10 else phone\n",
    "\n",
    "def safe_extract_text(soup, selector, default=\"\"):\n",
    "    element = soup.select_one(selector)\n",
    "    return element.get_text(strip=True) if element else default\n",
    "\n",
    "# Initialize 'data' as an empty list\n",
    "data = []  # This needs to be defined before it's used in data.append(...)\n",
    "\n",
    "# Data extraction function\n",
    "def extract_data_from_page(url, data):\n",
    "    logging.info(f\"Extracting data from: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Function to Close Google Ads\n",
    "    if \"#google_vignette\" in driver.current_url:\n",
    "        try:\n",
    "            driver.find_element(By.ID, \"close_button\").click()\n",
    "        except NoSuchElementException:\n",
    "            logging.warning(\"Google ad pop-up not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66e59e-a243-4d14-9640-ba2b5491c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse page content\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "department_name = safe_extract_text(soup, \"h1.departmentname\")\n",
    "title = safe_extract_text(soup, \"div.title\")\n",
    "\n",
    "# Extract department information\n",
    "department_info = soup.find(\"div\", class_=\"departmentinfo\")\n",
    "info_lines = department_info.get_text(separator=\"\\n\").splitlines() if department_info else []\n",
    "    \n",
    "first_name = info_lines[0].split()[0] if info_lines and len(info_lines[0].split()) > 0 else \"\"\n",
    "last_name = info_lines[0].split()[1] if info_lines and len(info_lines[0].split()) > 1 else \"\"\n",
    "building_name = info_lines[1] if len(info_lines) > 1 else \"\"\n",
    "address = info_lines[2] if len(info_lines) > 2 else \"\"\n",
    "    \n",
    "city_state_zip = info_lines[3] if len(info_lines) > 3 else \"\"\n",
    "city = city_state_zip.split(\",\")[0] if \",\" in city_state_zip else \"\"\n",
    "state = format_state(city_state_zip.split(\",\")[1].strip().split()[0]) if \",\" in city_state_zip else \"\"\n",
    "zip_code = city_state_zip.split()[-1] if len(city_state_zip.split()) > 1 else \"\"\n",
    "    \n",
    "# County extraction\n",
    "county = safe_extract_text(department_info, \"a\") if department_info else \"\"\n",
    "\n",
    "# Append the extracted data\n",
    "data.append({\n",
    "    \"department_name\": department_name,\n",
    "    \"title\": title,\n",
    "    \"first_name\": first_name,\n",
    "    \"last_name\": last_name,\n",
    "    \"building_name\": building_name,\n",
    "    \"address\": address,\n",
    "    \"city\": city,\n",
    "    \"state\": state,\n",
    "    \"zip_code\": zip_code,\n",
    "    \"county\": county\n",
    "})\n",
    "logging.info(f\"Data extracted for {department_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22adcf-f821-4766-a257-81ffa98145e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Extraction Process\n",
    "\n",
    "# Define base URL\n",
    "base_url = \"https://www.usacops.com/co/shrflist.html\"\n",
    "\n",
    "# Load the main page\n",
    "driver.get(base_url)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# Initialize empty list to store data\n",
    "data = []\n",
    "\n",
    "# Find both divs with the class \"centercolumnnested2all links within main page\"\n",
    "link_divs = soup.find_all(\"div\", class_=\"centercolumnnested2\")\n",
    "\n",
    "# Loop through each div and collect links\n",
    "for link_div in link_divs:\n",
    "    links = link_div.find_all(\"a\", href=True)\n",
    "    for link in links:\n",
    "        target_url = urljoin(base_url, link[\"href\"])\n",
    "        extract_data_from_page(target_url, data)\n",
    "        \n",
    "        # Delay adjust between requests to prevent timeout\n",
    "        time.sleep(5) # Adjust as needed for server load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5001f-14f3-4c7e-916b-1835da89b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data to CSV\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"department_name\", \"title\", \"first_name\", \"last_name\", \n",
    "    \"building_name\", \"address\", \"city\", \"state\", \"zip_code\", \"county\"\n",
    "])\n",
    "\n",
    "output_path = r\"C:\\Users\\jchan\\csi360_fire_police\\co_lefd_contact_num\\resources\\output\\extracted_data.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "logging.info(f\"Data successfully saved to {output_path}\")\n",
    "\n",
    "# Quit the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76bb63-175b-42e8-8439-1227e7cc3363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lefd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
